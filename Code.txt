

## Random Forest using Regression Tree

## Case Study -
## Data : Wine Quality data

## One of the wine production company is looking for the Rating solution to rate 
## different varieties of its white wines on the scale of 3 to 9, where 3 is the 
## poor quality and 9 is the most superior quality of the wine, they want to 
## consider all the available properties of the wines to make this decision
## The main objective is to find the significant attributes and use their relation
## with wine quality to come up with wine Ratings.

## Dependent variable - Wine quality (3-9)
## Independent variables - All other


import os

os.chdir("D:\Data Science Training\Data")

import pandas as pd

import numpy as np

data = pd.read_csv("winequality-white.csv",sep=';')


data.info()





## Missing data Handling


pd.isna(data.quality)

pd.isna(data.quality).value_counts()




#### 1.2  Categorical Data Handling 

data.info()


object_cols = list(data.select_dtypes(include=['category','object']))

object_cols


## 1.3 Feature Scaling



from sklearn import preprocessing

import pandas as pd

data_scaled = preprocessing.scale(data.iloc[:,[0,1,2,3,4,5,6,7,8,9,10]])

data1 = pd.DataFrame(data_scaled).join(data['quality'])

data1.columns = data.columns

data = data1


#### 1.4 Splitting data into Training and Test Data Sets

 

from sklearn.model_selection import train_test_split


data.info()

data_X = data.iloc[:,[0,1,2,3,4,5,6,7,8,9,10]]
data_y = data[:]['quality']


X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=100)

X_train.info()

y_train

X_test.info()

y_test

import seaborn as sns

sns.distplot(data.quality,kde=False)

sns.distplot(y_train,kde=False)

sns.distplot(y_test,kde=False)




## 1.5 Feature Selection -


cr = data.corr()

cr['quality']

sns.heatmap(cr,annot=True,cmap="coolwarm")


## Conclusion - Selected independent variables :  All

## building Classification Model


## 1.6 Build the Model


from sklearn.ensemble import RandomForestRegressor


rf_clf = RandomForestRegressor(n_estimators=5, max_features='auto', random_state=0)

#n_estimators  - The number of trees in the forest
#max_features  - The number of features to consider when looking for the best split

# Train the model using the training sets

rf_clf.fit(X_train,y_train)



## Predicting death_rate for test dataset using model

y_pred = rf_clf.predict(X_test)

y_pred=np.round(y_pred)



res = pd.DataFrame({'y_act':y_test,'y_pred':y_pred})





## 1.7 Model Evaluation - Confusion Matrix

from sklearn.metrics import confusion_matrix


cnf_matrix = confusion_matrix(y_test, y_pred)


print(cnf_matrix)



## Analyze the errors visually



sns.distplot(y_test,kde=False,

             hist_kws={"width":0.5,"alpha": 0.8, "color": "r"}

                       )

sns.distplot(y_pred,kde=False,

             hist_kws={"width":0.5,"alpha": 0.8, "color": "g"}

                       )